<?xml version="1.0" encoding="UTF-8"?>
<refentry version="5.0-subset Scilab" xml:id="twodpca" xml:lang="en"
          xmlns="http://docbook.org/ns/docbook"
          xmlns:xlink="http://www.w3.org/1999/xlink"
          xmlns:xi="http://www.w3.org/2001/XInclude"
          xmlns:svg="http://www.w3.org/2000/svg"
          xmlns:mml="http://www.w3.org/1998/Math/MathML"
          xmlns:html="http://www.w3.org/1999/xhtml"
          xmlns:db="http://docbook.org/ns/docbook">
  <info>
    <pubdate>November 2009</pubdate>
  </info>

  <refnamediv>
    <refname>twodpca</refname>

    <refpurpose>Two-Dimensional PCA</refpurpose>
  </refnamediv>

  <refsynopsisdiv>
    <title>Calling Sequence</title>

    <synopsis>[Y, X] = twodpca(A, K)</synopsis>
  </refsynopsisdiv>

  <refsection>
    <title>Parameters</title>

    <variablelist>
      <varlistentry>
        <term>A</term>

        <listitem>
          <para>m*n*d hypermat; m*n is the size of the sample matrix; d is the
          number of the sample</para>
        </listitem>
      </varlistentry>
    </variablelist>

    <variablelist>
      <varlistentry>
        <term>K</term>

        <listitem>
          <para>number of projection axis Xk; K &lt;= n</para>
        </listitem>
      </varlistentry>
    </variablelist>

    <variablelist>
      <varlistentry>
        <term>Y</term>

        <listitem>
          <para>m*K*d hypermat; m*K is the size of the feature matrix; each
          column is a projected feature vector Yk = A*Xk; d is the number of
          the sample</para>
        </listitem>
      </varlistentry>
    </variablelist>

    <variablelist>
      <varlistentry>
        <term>X</term>

        <listitem>
          <para>The set of projection axes; each column is a projection
          axis.</para>
        </listitem>
      </varlistentry>
    </variablelist>
  </refsection>

  <refsection>
    <title>Description</title>

    <para>Two-Dimensional principal component analysis (2DPCA) is to project
    an m*n sample matrix <emphasis>Ai</emphasis> onto an n-dimensional unitary
    column vector <emphasis>Xk</emphasis> by a linear transformation
    <literal>Yk = AiXk</literal>, to get an m-dimensional feature vector
    <emphasis>Y</emphasis><emphasis>k</emphasis>. <emphasis>K</emphasis>
    principal component vectors of sample <emphasis>Ai</emphasis> can be get
    from <literal>Yk = AiXk k=1,2,...,K</literal>. An m*K matrix <literal>B =
    [Y1, Y2, ..., YK]</literal> which is the feature matrix of
    <emphasis>Ai</emphasis> can be obtained.</para>
  </refsection>

  <refsection>
    <title>Authors</title>

    <simplelist>
      <member>Jia Wu &lt;jiawu83@gmail.com&gt;</member>
    </simplelist>
  </refsection>

  <refsection>
    <title>Bibliography</title>

    <para>J. Yang, D. Zhang, A. Frangi, and J. Yang. Two-dimensional pca: A
    new approach to appearance-based face representation and recognition. IEEE
    Trans. on Pattern Analysis and Machine Intelligence, 26(1):131â€“137,
    2004.</para>
  </refsection>

  <refsection>
    <title>Availability</title>

    <para>The latest version of OpenPR can be found at
    http://www.openpr.org.cn.</para>
  </refsection>

  <refsection>
    <title>See Also</title>

    <simplelist type="inline">
      <member><link linkend="pca2">pca2</link></member>
    </simplelist>
  </refsection>
</refentry>
