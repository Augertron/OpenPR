<?xml version="1.0" encoding="UTF-8"?>
<refentry version="5.0-subset Scilab" xml:id="wpca" xml:lang="en"
          xmlns="http://docbook.org/ns/docbook"
          xmlns:xlink="http://www.w3.org/1999/xlink"
          xmlns:xi="http://www.w3.org/2001/XInclude"
          xmlns:svg="http://www.w3.org/2000/svg"
          xmlns:mml="http://www.w3.org/1998/Math/MathML"
          xmlns:html="http://www.w3.org/1999/xhtml"
          xmlns:db="http://docbook.org/ns/docbook">
  <info>
    <author>
      <personname>Ran He</personname>
    </author>

    <pubdate>May 2009</pubdate>
  </info>

  <refnamediv>
    <refname>wpca</refname>

    <refpurpose>Weighted Principal Component Analysis</refpurpose>
  </refnamediv>

  <refsynopsisdiv>
    <title>Calling Sequence</title>

    <synopsis>[eig_vec, m_vec, eig_val] = wpca(Train_Patterns, weight)</synopsis>
  </refsynopsisdiv>

  <refsection>
    <title>Parameters</title>

    <variablelist>
      <varlistentry>
        <term>Train_Patterns</term>

        <listitem>
          <para>Data matrix. Each column vector is a data point.</para>
        </listitem>
      </varlistentry>

      <varlistentry>
        <term>weight</term>

        <listitem>
          <para>A column vector whose length is equal to number of data
          points.</para>
        </listitem>
      </varlistentry>

      <varlistentry>
        <term>eig_vec</term>

        <listitem>
          <para>Each column is an eigvector. eig_vec'*eig_vec=I.</para>
        </listitem>
      </varlistentry>

      <varlistentry>
        <term>m_vec</term>

        <listitem>
          <para>Data center.</para>
        </listitem>
      </varlistentry>

      <varlistentry>
        <term>eig_val</term>

        <listitem>
          <para>he sorted eigvalue of WPCA algorithm.</para>
        </listitem>
      </varlistentry>
    </variablelist>
  </refsection>

  <refsection>
    <title>Description</title>

    <para>The function is used for weighted principal component
    analysis.</para>
  </refsection>

  <refsection>
    <title>Examples</title>

    <programlisting role="example">       e.g.1: learn the principal component of a dataset
             Train_Patterns = rand(2,100);   //number of dimension is 2 number of data points is 100
             weight = ones(100,1);           //A column vector of weight
             [eig_vec,m_vec,eig_val] = wpca(Train_Patterns,weight);

       e.g.2: a graph example of principal component
             rotation = [7 -cos(3.14/4);sin(3.14/4) 1];
             Train_Patterns = rand(2,100);
             Train_Patterns = rotation* Train_Patterns;                  
             weight = ones(100,1) ;                                    //equal weight
             plot2d(Train_Patterns(1,:),Train_Patterns(2,:),style=-4); //plot the data points
             [eig_vec,m_vec,eig_val] = wpca(Train_Patterns,weight);
             plot2d(m_vec(1),m_vec(2),style=-5);                       //plot the mean vector
             //plot the first principal component
             x=-1:0.1:7;
             y=(eig_vec(2,1)/eig_vec(1,1))*(x-m_vec(1))+m_vec(2);
             plot2d(x,y,style=2);
             legends(["data";"data center";"eigen vector"],[-4,-5,2], with_box=%f, opt="?")</programlisting>
  </refsection>

  <refsection>
    <title>Authors</title>

    <simplelist>
      <member>Ran He &lt;rhe@nlpr.ia.ac.cn&gt;</member>
    </simplelist>
  </refsection>

  <refsection>
    <title>Bibliography</title>

    <para>C.M. Bishop. Pattern Recognition and Machine Learning. Information
    Science and Statistics, 2006</para>
  </refsection>

  <refsection>
    <title>Availability</title>

    <para>The latest version of OpenPR can be found at
    http://www.openpr.org.cn.</para>
  </refsection>

  <refsection>
    <title>See Also</title>

    <simplelist type="inline">
      <member><link linkend="pca2">pca2</link></member>

      <member><link linkend="mlda">mlda</link></member>
    </simplelist>
  </refsection>
</refentry>
